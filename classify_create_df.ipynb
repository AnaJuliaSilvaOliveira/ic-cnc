{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfa908d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy.io as sc\n",
    "import scipy.stats\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.fftpack import fft, ifft \n",
    "from os import listdir\n",
    "import os.path\n",
    "import shutil \n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9862b166",
   "metadata": {},
   "source": [
    "# Creating folder called Corrected and deleting previous folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c72b914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# success = True\n",
    "# while success:\n",
    "#     try:\n",
    "#         shutil.rmtree('corrected')\n",
    "#         success = False\n",
    "#     except:\n",
    "#         success = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee16f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# success = True\n",
    "# while success:\n",
    "#     try: \n",
    "#         list_of_folders = listdir(\"cutting_tests_processed\")\n",
    "#         for folder in list_of_folders:\n",
    "#             os.makedirs(f'corrected/{folder}')\n",
    "#         success = False\n",
    "#     except:\n",
    "#         success = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be043984",
   "metadata": {},
   "source": [
    "# Manually classifing data for the presence of chatter into new folder called corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "400add08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Print graphs to use as references\n",
    "\n",
    "# path = 'split_cutting_tests_processed/2inch_stickout'\n",
    "\n",
    "# sem_chatter = [j for j in listdir(path) if j[0] == 's' and\n",
    "#                                         '_noise_added' not in j]\n",
    "\n",
    "# com_chatter = [j for j in listdir(path) if j[0] == 'c' and\n",
    "#                                         '_noise_added' not in j]\n",
    "\n",
    "\n",
    "\n",
    "# for j in range(5):\n",
    "#     plot = pd.read_csv(f'{path}/{sem_chatter[j]}')\n",
    "#     fig, ax = plt.subplots(1,2, figsize = (10,4))\n",
    "\n",
    "#     ax[0].plot(plot['t'], plot['y'])\n",
    "#     fft = np.fft.fft(plot['y'])\n",
    "#     fftfreq = np.fft.fftfreq(len(plot['t']), plot['t'][1] - plot['t'][0])\n",
    "#     ax[1].plot(fftfreq[10:int(len(fft)/2)], np.abs(fft[10:int(len(fft)/2)])/len(fft), c = 'k')\n",
    "#     fig.suptitle(sem_chatter[j])\n",
    "\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "# for j in range(5):\n",
    "#     plot = pd.read_csv(f'{path}/{com_chatter[j]}')\n",
    "#     fig, ax = plt.subplots(1,2, figsize = (10,4))\n",
    "\n",
    "#     ax[0].plot(plot['t'], plot['y'])\n",
    "#     fft = np.fft.fft(plot['y'])\n",
    "#     fftfreq = np.fft.fftfreq(len(plot['t']), plot['t'][1] - plot['t'][0])\n",
    "#     ax[1].plot(fftfreq[10:int(len(fft)/2)], np.abs(fft[10:int(len(fft)/2)])/len(fft), c = 'k')\n",
    "#     fig.suptitle(com_chatter[j])\n",
    "\n",
    "\n",
    "#     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e07ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main_():\n",
    "#     '''\n",
    "#     changes the split files first letter to match it's correct classification to\n",
    "#     the presence of chatter according to the users input and saves the file with\n",
    "#     the corect name to the folder \"corrected\" with the same folders as \n",
    "#     split_cutting_tests_processed.\n",
    "#     '''\n",
    "#     folders = listdir('split_cutting_tests_processed')\n",
    "#     print(folders)\n",
    "#     # folder = ''\n",
    "#     path_split = 'split_cutting_tests_processed'\n",
    "#     path_corrected = 'corrected'\n",
    "\n",
    "    \n",
    "#     for folder in folders:\n",
    "#         list_of_files = listdir(f'{path_split}/{folder}') \n",
    "#         for file in list_of_files:\n",
    "#             if file[0] != 's' and file[-5] != 'd':\n",
    "#                 print(f'Folder: {folder}') \n",
    "#                 print(f'File: {file}')\n",
    "#                 print('')\n",
    "\n",
    "#                 plot = pd.read_csv(f'{path_split}/{folder}/{file}')\n",
    "\n",
    "#                 # data = sc.loadmat(f'cutting_tests_processed/{folder}/{file[0:9]}.mat')\n",
    "#                 # lim = pd.DataFrame.from_dict(data['tsDS'][:,:])\n",
    "#                 # lim.rename({0: 't', 1: 'y'}, axis=1, inplace=True)\n",
    "#                 # limit = np.fft.fft(lim['y']).max()\n",
    "\n",
    "#                 fft = np.fft.fft(plot['y'])\n",
    "#                 fftfreq = np.fft.fftfreq(len(plot['t']), plot['t'][1] - plot['t'][0])\n",
    "\n",
    "#                 # ploting\n",
    "#                 fig, ax = plt.subplots(1,2, figsize = (10,4))\n",
    "#                 # plt.ylim(0,limit)\n",
    "#                 ax[0].plot(plot['t'], plot['y'])\n",
    "#                 ax[1].plot(fftfreq[10:len(fft)//2], np.abs(fft[10:len(fft)//2])/len(fft), c = 'k')\n",
    "#                 fig.suptitle(file)\n",
    "#                 plt.show()\n",
    "\n",
    "#                 # classifing \n",
    "#                 print(\"c = has chatter \\n s = no chatter \\n \\\"stop\\\" \\n \\\"pass\\\"\")\n",
    "#                 presence = input('')\n",
    "#                 if presence == 'stop':\n",
    "#                     break\n",
    "#                 if presence == 'pass':\n",
    "#                     continue\n",
    "\n",
    "#                 # saving files\n",
    "#                 shutil.copyfile(f'{path_split}/{folder}/{file}', f'{path_corrected}/{folder}/{presence}{file[1:]}')\n",
    "#                 shutil.copyfile(f'{path_split}/{folder}/{file[:-4]}_noise_added.csv', f'{path_corrected}/{folder}/{presence}{file[1:-4]}_noise_added.csv')\n",
    "\n",
    "#                 clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45b2e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eba658f",
   "metadata": {},
   "source": [
    "# Creating a new data frame with math features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dd1429",
   "metadata": {},
   "source": [
    "Defining the functions used in the creation of the dataframe as to keep the formulas more organized and easy to read. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82603bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thd(data_): # true harmonic distortion\n",
    "    sq_sum = 0.0\n",
    "    for r in range(len(data_)):\n",
    "        sq_sum = sq_sum + data_[r]**2\n",
    "    sq_harmonics = sq_sum - max(data_)**2\n",
    "    return 100*sq_harmonics**0.5 / max(data_)\n",
    "\n",
    "def rms(data_):\n",
    "    return np.sqrt(np.mean(data_**2))\n",
    "\n",
    "def amp(data_):\n",
    "    return max(data_) - min(data_)\n",
    "\n",
    "def SRA(data_):\n",
    "    return np.mean(np.sqrt(np.abs(data_)))**2\n",
    "\n",
    "def crest(data_):\n",
    "    return max(np.abs(data_))/np.sqrt(np.mean(data_**2))\n",
    "\n",
    "def impulse(data_):\n",
    "    return max(np.abs(data_))/np.mean(abs(data_))\n",
    "\n",
    "def margin(data_):\n",
    "    return max(abs(data_))/np.mean(np.sqrt(np.abs(data_)))**2\n",
    "\n",
    "def freq_max(data_):\n",
    "    data_ = data_[100:]\n",
    "    # sorted(np.array(scipy.fftpack.fft(file['y'].values)))[-2]\n",
    "    peak_freq = data_['fftfreq'][data_['fft'] == data_['fft'].max()].values[0]\n",
    "#    print(peak_freq)\n",
    "    return peak_freq\n",
    "\n",
    "    \n",
    "def freq_sec_highest(data_):\n",
    "    # sorted(np.array(scipy.fftpack.fft(file['fftfreq'].values)))[-3]\n",
    "    data_ = data_[100:]\n",
    "    data_sorted = data_.sort_values(by = ['fft'], ascending = False)\n",
    "    return data_sorted['fftfreq'].to_numpy()[1]\n",
    "\n",
    "def fft_mean(data_):\n",
    "    ffts_array = np.array([np.abs(complex(i)) for i in data_['fft'].to_numpy()])\n",
    "    return ffts_array.mean()\n",
    "\n",
    "# def freq_pico(data_):\n",
    "#     # sorted(np.array(scipy.fftpack.fft(file['y'].values)))[-2]\n",
    "#     return data_['fftfreq'].max()\n",
    "\n",
    "#         cols['freq_max'].append(scipy.fftpack.fft(file['y'].values).max()) # https://gist.github.com/endolith/255291\n",
    "#         cols['freq_sec_highest'].append(sorted(np.array(scipy.fftpack.fft(file['y'].values)))[-2]) \n",
    "#         cols['freq_mean'].append(scipy.fftpack.fft(file['y'].values).mean()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b7b8e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Creating the data frame of math equations outputs.\n",
    "'''\n",
    "cols = {'Experiment': [],\n",
    "        'chatter_presence': [],\n",
    "        'med': [],\n",
    "        'std': [],\n",
    "        'rms': [],\n",
    "        'curtose': [],\n",
    "        'distortion': [],\n",
    "        'amplitude': [],\n",
    "        'sra': [],\n",
    "        'crest': [],\n",
    "        'impulse': [],\n",
    "        'margin': [],\n",
    "        'max': [],\n",
    "        'freq_max': [],\n",
    "        'freq_sec_highest': [],\n",
    "        'fft_mean': []}\n",
    "\n",
    "path = \"corrected\"\n",
    "list_of_folders = listdir(path)\n",
    "for folder in list_of_folders:\n",
    "    list_of_files = listdir(f'{path}/{folder}')\n",
    "    for file in list_of_files:\n",
    "        cols['Experiment'].append(f'{file[:-4]}')\n",
    "        cols['chatter_presence'].append(f'{file[:1]}')\n",
    "        \n",
    "        # print(file)\n",
    "        file = pd.read_csv(f'{path}/{folder}/{file}', index_col=0)\n",
    "                \n",
    "        cols['med'].append(file['y'].mean())\n",
    "        cols['std'].append(file['y'].std())\n",
    "        cols['rms'].append(rms(file['y']))\n",
    "        \n",
    "        cols['curtose'].append(scipy.stats.kurtosis(file['y']))\n",
    "        cols['distortion'].append(thd(file['y']))\n",
    "        cols['amplitude'].append(amp(file['y']))\n",
    "        cols['sra'].append(SRA(file['y']))\n",
    "        \n",
    "        cols['crest'].append(crest(file['y']))\n",
    "        cols['impulse'].append(impulse(file['y']))\n",
    "        cols['margin'].append(margin(file['y']))\n",
    "        cols['max'].append(file['y'].max())\n",
    "        \n",
    "        cols['freq_max'].append(freq_max(file)) # https://gist.github.com/endolith/255291\n",
    "        cols['freq_sec_highest'].append(freq_sec_highest(file)) \n",
    "        cols['fft_mean'].append(fft_mean(file))\n",
    "\n",
    "        clear_output()\n",
    "\n",
    "dataframe = pd.DataFrame(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87612f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>chatter_presence</th>\n",
       "      <th>med</th>\n",
       "      <th>std</th>\n",
       "      <th>rms</th>\n",
       "      <th>curtose</th>\n",
       "      <th>distortion</th>\n",
       "      <th>amplitude</th>\n",
       "      <th>sra</th>\n",
       "      <th>crest</th>\n",
       "      <th>impulse</th>\n",
       "      <th>margin</th>\n",
       "      <th>max</th>\n",
       "      <th>freq_max</th>\n",
       "      <th>freq_sec_highest</th>\n",
       "      <th>fft_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s_320_045_split_1</td>\n",
       "      <td>s</td>\n",
       "      <td>0.005482</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.005940</td>\n",
       "      <td>-0.684501</td>\n",
       "      <td>13046.608858</td>\n",
       "      <td>0.019401</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>2.709846</td>\n",
       "      <td>2.934679</td>\n",
       "      <td>3.084994</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>3075.253849</td>\n",
       "      <td>3314.593371</td>\n",
       "      <td>0.617542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s_320_015_split_0</td>\n",
       "      <td>s</td>\n",
       "      <td>0.005475</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.005857</td>\n",
       "      <td>-0.254890</td>\n",
       "      <td>7052.357014</td>\n",
       "      <td>0.041907</td>\n",
       "      <td>0.005266</td>\n",
       "      <td>4.755544</td>\n",
       "      <td>5.084255</td>\n",
       "      <td>5.289695</td>\n",
       "      <td>0.027854</td>\n",
       "      <td>119.866400</td>\n",
       "      <td>696.665119</td>\n",
       "      <td>0.406478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s_320_020_split_3</td>\n",
       "      <td>s</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.005835</td>\n",
       "      <td>-1.170823</td>\n",
       "      <td>8819.340916</td>\n",
       "      <td>0.010459</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>1.792693</td>\n",
       "      <td>1.904703</td>\n",
       "      <td>1.972551</td>\n",
       "      <td>0.010460</td>\n",
       "      <td>-119.598804</td>\n",
       "      <td>-1207.787922</td>\n",
       "      <td>0.159834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c_770_005_split_3</td>\n",
       "      <td>c</td>\n",
       "      <td>0.005414</td>\n",
       "      <td>0.040638</td>\n",
       "      <td>0.040996</td>\n",
       "      <td>0.898666</td>\n",
       "      <td>4733.248435</td>\n",
       "      <td>0.416909</td>\n",
       "      <td>0.026842</td>\n",
       "      <td>5.159852</td>\n",
       "      <td>6.625808</td>\n",
       "      <td>7.880688</td>\n",
       "      <td>0.205375</td>\n",
       "      <td>-945.862463</td>\n",
       "      <td>-845.862907</td>\n",
       "      <td>6.028744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s_320_005_split_1_noise_added</td>\n",
       "      <td>s</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.005955</td>\n",
       "      <td>-0.221540</td>\n",
       "      <td>8084.124352</td>\n",
       "      <td>0.022319</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>2.765787</td>\n",
       "      <td>2.989542</td>\n",
       "      <td>3.140532</td>\n",
       "      <td>0.016471</td>\n",
       "      <td>3762.600000</td>\n",
       "      <td>-3762.600000</td>\n",
       "      <td>0.239377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>c_570_012_split_1_noise_added</td>\n",
       "      <td>c</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.006235</td>\n",
       "      <td>0.603812</td>\n",
       "      <td>7292.776694</td>\n",
       "      <td>0.027757</td>\n",
       "      <td>0.005170</td>\n",
       "      <td>3.065853</td>\n",
       "      <td>3.423945</td>\n",
       "      <td>3.697408</td>\n",
       "      <td>0.019116</td>\n",
       "      <td>1049.000000</td>\n",
       "      <td>-1049.000000</td>\n",
       "      <td>0.294652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>c_770_005_split_3_noise_added</td>\n",
       "      <td>c</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>0.010397</td>\n",
       "      <td>1.034704</td>\n",
       "      <td>1766.022171</td>\n",
       "      <td>0.087902</td>\n",
       "      <td>0.007025</td>\n",
       "      <td>4.583835</td>\n",
       "      <td>5.757399</td>\n",
       "      <td>6.784075</td>\n",
       "      <td>0.040242</td>\n",
       "      <td>1175.592063</td>\n",
       "      <td>-1175.592063</td>\n",
       "      <td>0.315492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>c_570_012_split_2_noise_added</td>\n",
       "      <td>c</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.005860</td>\n",
       "      <td>-0.212874</td>\n",
       "      <td>9666.131901</td>\n",
       "      <td>0.016478</td>\n",
       "      <td>0.005264</td>\n",
       "      <td>2.313178</td>\n",
       "      <td>2.470556</td>\n",
       "      <td>2.575268</td>\n",
       "      <td>0.013556</td>\n",
       "      <td>-19.400000</td>\n",
       "      <td>-1067.600000</td>\n",
       "      <td>0.239460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>c_570_012_split_1</td>\n",
       "      <td>c</td>\n",
       "      <td>0.005461</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>0.006201</td>\n",
       "      <td>0.663894</td>\n",
       "      <td>7286.361721</td>\n",
       "      <td>0.026717</td>\n",
       "      <td>0.005174</td>\n",
       "      <td>3.068551</td>\n",
       "      <td>3.415217</td>\n",
       "      <td>3.677729</td>\n",
       "      <td>0.019029</td>\n",
       "      <td>3492.732536</td>\n",
       "      <td>3601.931990</td>\n",
       "      <td>0.439309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>s_570_008_split_1</td>\n",
       "      <td>s</td>\n",
       "      <td>0.005507</td>\n",
       "      <td>0.001837</td>\n",
       "      <td>0.005805</td>\n",
       "      <td>0.117230</td>\n",
       "      <td>8839.001829</td>\n",
       "      <td>0.020372</td>\n",
       "      <td>0.005341</td>\n",
       "      <td>2.645544</td>\n",
       "      <td>2.787158</td>\n",
       "      <td>2.875368</td>\n",
       "      <td>0.015358</td>\n",
       "      <td>4388.414224</td>\n",
       "      <td>3522.406755</td>\n",
       "      <td>0.419257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>628 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Experiment chatter_presence       med       std  \\\n",
       "0                s_320_045_split_1                s  0.005482  0.002285   \n",
       "1                s_320_015_split_0                s  0.005475  0.002081   \n",
       "2                s_320_020_split_3                s  0.005492  0.001971   \n",
       "3                c_770_005_split_3                c  0.005414  0.040638   \n",
       "4    s_320_005_split_1_noise_added                s  0.005498  0.002290   \n",
       "..                             ...              ...       ...       ...   \n",
       "623  c_570_012_split_1_noise_added                c  0.005464  0.003003   \n",
       "624  c_770_005_split_3_noise_added                c  0.005426  0.008870   \n",
       "625  c_570_012_split_2_noise_added                c  0.005484  0.002065   \n",
       "626              c_570_012_split_1                c  0.005461  0.002938   \n",
       "627              s_570_008_split_1                s  0.005507  0.001837   \n",
       "\n",
       "          rms   curtose    distortion  amplitude       sra     crest  \\\n",
       "0    0.005940 -0.684501  13046.608858   0.019401  0.005217  2.709846   \n",
       "1    0.005857 -0.254890   7052.357014   0.041907  0.005266  4.755544   \n",
       "2    0.005835 -1.170823   8819.340916   0.010459  0.005303  1.792693   \n",
       "3    0.040996  0.898666   4733.248435   0.416909  0.026842  5.159852   \n",
       "4    0.005955 -0.221540   8084.124352   0.022319  0.005245  2.765787   \n",
       "..        ...       ...           ...        ...       ...       ...   \n",
       "623  0.006235  0.603812   7292.776694   0.027757  0.005170  3.065853   \n",
       "624  0.010397  1.034704   1766.022171   0.087902  0.007025  4.583835   \n",
       "625  0.005860 -0.212874   9666.131901   0.016478  0.005264  2.313178   \n",
       "626  0.006201  0.663894   7286.361721   0.026717  0.005174  3.068551   \n",
       "627  0.005805  0.117230   8839.001829   0.020372  0.005341  2.645544   \n",
       "\n",
       "      impulse    margin       max     freq_max  freq_sec_highest  fft_mean  \n",
       "0    2.934679  3.084994  0.016095  3075.253849       3314.593371  0.617542  \n",
       "1    5.084255  5.289695  0.027854   119.866400        696.665119  0.406478  \n",
       "2    1.904703  1.972551  0.010460  -119.598804      -1207.787922  0.159834  \n",
       "3    6.625808  7.880688  0.205375  -945.862463       -845.862907  6.028744  \n",
       "4    2.989542  3.140532  0.016471  3762.600000      -3762.600000  0.239377  \n",
       "..        ...       ...       ...          ...               ...       ...  \n",
       "623  3.423945  3.697408  0.019116  1049.000000      -1049.000000  0.294652  \n",
       "624  5.757399  6.784075  0.040242  1175.592063      -1175.592063  0.315492  \n",
       "625  2.470556  2.575268  0.013556   -19.400000      -1067.600000  0.239460  \n",
       "626  3.415217  3.677729  0.019029  3492.732536       3601.931990  0.439309  \n",
       "627  2.787158  2.875368  0.015358  4388.414224       3522.406755  0.419257  \n",
       "\n",
       "[628 rows x 16 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e9e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv('math_outputs.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c29a9e09",
   "metadata": {},
   "source": [
    "# create df for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5181c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    THIS ONE USES THE UNSPLIT (WITHOUT NOISE)\n",
    "\"\"\"\n",
    "# ''' Creating the data frame of math equations outputs.\n",
    "# '''\n",
    "# clust = {'Experiment': [],\n",
    "#         'chatter_presence': [],\n",
    "#         'med': [],\n",
    "#         'std': [],\n",
    "#         'rms': [],\n",
    "#         'curtose': [],\n",
    "#         'distortion': [],\n",
    "#         'amplitude': [],\n",
    "#         'sra': [],\n",
    "#         'crest': [],\n",
    "#         'impulse': [],\n",
    "#         'margin': [],\n",
    "#         'max': [],\n",
    "#         'freq_max': [],\n",
    "#         'freq_sec_highest': [],\n",
    "#         'fft_mean': []}\n",
    "\n",
    "# path = \"cutting_tests_processed\"\n",
    "# list_of_folders = listdir(path)\n",
    "# for folder in list_of_folders:\n",
    "#     list_of_files = listdir(f'{path}/{folder}')\n",
    "#     for file in list_of_files:\n",
    "#         clust['Experiment'].append(f'{file[:-4]}')\n",
    "#         clust['chatter_presence'].append(f'{file[:1]}')\n",
    "        \n",
    "#         # print(file)\n",
    "#         data = sc.loadmat(f'{path}/{folder}/{file}')\n",
    "#         file = pd.DataFrame.from_dict(data['tsDS'][:,:])\n",
    "#         file.rename({0: 't', 1: 'y'}, axis=1, inplace=True)\n",
    "        \n",
    "#         freq = np.fft.fftfreq(len(file['t']), file['t'][1] - file['t'][0])\n",
    "#         yf = np.fft.fft(file['y'])\n",
    "#         file['fft'] = yf\n",
    "#         file['fftfreq'] = freq # omega\n",
    "                \n",
    "#         clust['med'].append(file['y'].mean())\n",
    "#         clust['std'].append(file['y'].std())\n",
    "#         clust['rms'].append(rms(file['y']))\n",
    "        \n",
    "#         clust['curtose'].append(scipy.stats.kurtosis(file['y']))\n",
    "#         clust['distortion'].append(thd(file['y']))\n",
    "#         clust['amplitude'].append(amp(file['y']))\n",
    "#         clust['sra'].append(SRA(file['y']))\n",
    "        \n",
    "#         clust['crest'].append(crest(file['y']))\n",
    "#         clust['impulse'].append(impulse(file['y']))\n",
    "#         clust['margin'].append(margin(file['y']))\n",
    "#         clust['max'].append(file['y'].max())\n",
    "        \n",
    "#         clust['freq_max'].append(freq_max(file)) # https://gist.github.com/endolith/255291\n",
    "#         clust['freq_sec_highest'].append(freq_sec_highest(file)) \n",
    "#         clust['fft_mean'].append(fft_mean(file))\n",
    "\n",
    "#         clear_output()\n",
    "\n",
    "# dataframe_cluster = pd.DataFrame(clust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8e41821",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Creating the data frame of math equations outputs.\n",
    "'''\n",
    "clust = {'Experiment': [],\n",
    "        'chatter_presence': [],\n",
    "        'med': [],\n",
    "        'std': [],\n",
    "        'rms': [],\n",
    "        'curtose': [],\n",
    "        'distortion': [],\n",
    "        'amplitude': [],\n",
    "        'sra': [],\n",
    "        'crest': [],\n",
    "        'impulse': [],\n",
    "        'margin': [],\n",
    "        'max': [],\n",
    "        'freq_max': [],\n",
    "        'freq_sec_highest': [],\n",
    "        'fft_mean': []}\n",
    "\n",
    "path = \"split_cutting_tests_processed\"\n",
    "list_of_folders = listdir(path)\n",
    "for folder in list_of_folders:\n",
    "    list_of_files = listdir(f'{path}/{folder}')\n",
    "    for file in list_of_files:\n",
    "        if file[-5] != 'd':\n",
    "            clust['Experiment'].append(f'{file[:-4]}')\n",
    "            clust['chatter_presence'].append(f'{file[:1]}')\n",
    "            \n",
    "            file = pd.read_csv(f'{path}/{folder}/{file}', index_col=0)\n",
    "                    \n",
    "            clust['med'].append(file['y'].mean())\n",
    "            clust['std'].append(file['y'].std())\n",
    "            clust['rms'].append(rms(file['y']))\n",
    "            \n",
    "            clust['curtose'].append(scipy.stats.kurtosis(file['y']))\n",
    "            clust['distortion'].append(thd(file['y']))\n",
    "            clust['amplitude'].append(amp(file['y']))\n",
    "            clust['sra'].append(SRA(file['y']))\n",
    "            \n",
    "            clust['crest'].append(crest(file['y']))\n",
    "            clust['impulse'].append(impulse(file['y']))\n",
    "            clust['margin'].append(margin(file['y']))\n",
    "            clust['max'].append(file['y'].max())\n",
    "            \n",
    "            clust['freq_max'].append(freq_max(file)) # https://gist.github.com/endolith/255291\n",
    "            clust['freq_sec_highest'].append(freq_sec_highest(file)) \n",
    "            clust['fft_mean'].append(fft_mean(file))\n",
    "\n",
    "            clear_output()\n",
    "\n",
    "dataframe_cluster = pd.DataFrame(clust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7abc46ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>chatter_presence</th>\n",
       "      <th>med</th>\n",
       "      <th>std</th>\n",
       "      <th>rms</th>\n",
       "      <th>curtose</th>\n",
       "      <th>distortion</th>\n",
       "      <th>amplitude</th>\n",
       "      <th>sra</th>\n",
       "      <th>crest</th>\n",
       "      <th>impulse</th>\n",
       "      <th>margin</th>\n",
       "      <th>max</th>\n",
       "      <th>freq_max</th>\n",
       "      <th>freq_sec_highest</th>\n",
       "      <th>fft_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s_320_045_split_1</td>\n",
       "      <td>s</td>\n",
       "      <td>0.005482</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.005940</td>\n",
       "      <td>-0.684501</td>\n",
       "      <td>13046.608858</td>\n",
       "      <td>0.019401</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>2.709846</td>\n",
       "      <td>2.934679</td>\n",
       "      <td>3.084994</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>3075.253849</td>\n",
       "      <td>3314.593371</td>\n",
       "      <td>0.617542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s_320_015_split_0</td>\n",
       "      <td>s</td>\n",
       "      <td>0.005475</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.005857</td>\n",
       "      <td>-0.254890</td>\n",
       "      <td>7052.357014</td>\n",
       "      <td>0.041907</td>\n",
       "      <td>0.005266</td>\n",
       "      <td>4.755544</td>\n",
       "      <td>5.084255</td>\n",
       "      <td>5.289695</td>\n",
       "      <td>0.027854</td>\n",
       "      <td>119.866400</td>\n",
       "      <td>696.665119</td>\n",
       "      <td>0.406478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s_320_020_split_3</td>\n",
       "      <td>s</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.005835</td>\n",
       "      <td>-1.170823</td>\n",
       "      <td>8819.340916</td>\n",
       "      <td>0.010459</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>1.792693</td>\n",
       "      <td>1.904703</td>\n",
       "      <td>1.972551</td>\n",
       "      <td>0.010460</td>\n",
       "      <td>-119.598804</td>\n",
       "      <td>-1207.787922</td>\n",
       "      <td>0.159834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c_770_005_split_3</td>\n",
       "      <td>c</td>\n",
       "      <td>0.005414</td>\n",
       "      <td>0.040638</td>\n",
       "      <td>0.040996</td>\n",
       "      <td>0.898666</td>\n",
       "      <td>4733.248435</td>\n",
       "      <td>0.416909</td>\n",
       "      <td>0.026842</td>\n",
       "      <td>5.159852</td>\n",
       "      <td>6.625808</td>\n",
       "      <td>7.880688</td>\n",
       "      <td>0.205375</td>\n",
       "      <td>-945.862463</td>\n",
       "      <td>-845.862907</td>\n",
       "      <td>6.028744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c_770_002_split_0</td>\n",
       "      <td>c</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>0.014140</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>3.312443</td>\n",
       "      <td>1899.488742</td>\n",
       "      <td>0.160458</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>5.493718</td>\n",
       "      <td>7.627771</td>\n",
       "      <td>9.475498</td>\n",
       "      <td>0.077174</td>\n",
       "      <td>933.575105</td>\n",
       "      <td>959.974401</td>\n",
       "      <td>1.305385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Experiment chatter_presence       med       std       rms   curtose  \\\n",
       "0  s_320_045_split_1                s  0.005482  0.002285  0.005940 -0.684501   \n",
       "1  s_320_015_split_0                s  0.005475  0.002081  0.005857 -0.254890   \n",
       "2  s_320_020_split_3                s  0.005492  0.001971  0.005835 -1.170823   \n",
       "3  c_770_005_split_3                c  0.005414  0.040638  0.040996  0.898666   \n",
       "4  c_770_002_split_0                c  0.005469  0.014140  0.015160  3.312443   \n",
       "\n",
       "     distortion  amplitude       sra     crest   impulse    margin       max  \\\n",
       "0  13046.608858   0.019401  0.005217  2.709846  2.934679  3.084994  0.016095   \n",
       "1   7052.357014   0.041907  0.005266  4.755544  5.084255  5.289695  0.027854   \n",
       "2   8819.340916   0.010459  0.005303  1.792693  1.904703  1.972551  0.010460   \n",
       "3   4733.248435   0.416909  0.026842  5.159852  6.625808  7.880688  0.205375   \n",
       "4   1899.488742   0.160458  0.008789  5.493718  7.627771  9.475498  0.077174   \n",
       "\n",
       "      freq_max  freq_sec_highest  fft_mean  \n",
       "0  3075.253849       3314.593371  0.617542  \n",
       "1   119.866400        696.665119  0.406478  \n",
       "2  -119.598804      -1207.787922  0.159834  \n",
       "3  -945.862463       -845.862907  6.028744  \n",
       "4   933.575105        959.974401  1.305385  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7580ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_cluster.to_csv(\"for_clustering_math_outputs.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
